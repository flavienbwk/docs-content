---
meta:
  title: Data, privacy, and security for Scaleway's AI services
  description: Data, privacy, and security for Scaleway's AI services
content:
  h1: Data, privacy, and security for Scaleway's AI services
  paragraph: Data, privacy, and security for Scaleway's AI services
tags:
categories:
  - ai-data
---

## Data processing by Scaleway AI services

### Data Processed by Managed Inference

* **Input Data**: Scaleway processes input data, including prompts and parameters, to generate the requested content.
* **Metadata**: Scaleway processes metadata related to the use of Scaleway-owned interfaces (such as the console and CLI) during inference. This data is used to enhance services and improve customer experience.

### Scaleway AI serviced data processing practices

### Data usage

Scaleway’s models are stateless, meaning no prompts or generated content are stored within the model. Furthermore, neither prompts nor generations are used to train, retrain, or improve the base models.

<Message type="important">
    Your prompts (inputs) and completions (outputs), embeddings, and training data:
    * are NOT available to other customers.
    * are NOT accessible by the creator of the LLM.
    * are NOT used to improve the LLM.
    * are NOT used to enhance any Scaleway or third-party products or services.
    * are NOT utilized to improve Scaleway models (all models are stateless) automatically.

    Scaleway controls the Managed Inference service entirely. Scaleway hosts the LLM on its infrastructure, ensuring the service does not interact with third-party services.
</Message>

### Data storage

Inputs and outputs processed during inference are considered customer data. Scaleway does not log this data without the customer’s explicit permission, which would be provided by opting into a feature set not yet available.

### Data security

Models deployed or consumed for inference are hosted in Europe within the data center region specified by the customer. All traffic to and from the inference server is encrypted using in-transit TLS encryption to ensure complete data protection. Public-facing endpoints are secured with API key tokens. Additionally, the server can be hosted in a Virtual Private Cloud (VPC) within private subnets, and access can be restricted by allowed IP ranges.